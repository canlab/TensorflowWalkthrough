{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/clayton/science/CANlab/WAViMedEEG/PainStudyFiles/csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../science/CANlab/WAViMedEEG/PainStudyFiles/csv/')\n",
    "#os.listdir()\n",
    "os.getcwd() #'../science/CANlab/WAViMedEEG/PainStudyFiles/csv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of csv files to be loaded are those in the current directory\n",
    "filenames=sorted_alphanumeric(os.listdir())\n",
    "n=len(filenames)\n",
    "\n",
    "#print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (OrderedDict([(C1, (1,)), (C2, (1,)), (C3, (1,)), (C4, (1,)), (C5, (1,)), (C6, (1,)), (C7, (1,)), (C8, (1,)), (C9, (1,)), (C10, (1,)), (C11, (1,)), (C12, (1,)), (C13, (1,)), (C14, (1,)), (C15, (1,)), (C16, (1,)), (C17, (1,)), (C18, (1,)), (C19, (1,))]), (1,)), types: (OrderedDict([(C1, tf.int32), (C2, tf.int32), (C3, tf.int32), (C4, tf.int32), (C5, tf.int32), (C6, tf.int32), (C7, tf.int32), (C8, tf.int32), (C9, tf.int32), (C10, tf.int32), (C11, tf.int32), (C12, tf.int32), (C13, tf.int32), (C14, tf.int32), (C15, tf.int32), (C16, tf.int32), (C17, tf.int32), (C18, tf.int32), (C19, tf.int32)]), tf.int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.make_csv_dataset(\n",
    "    filenames,\n",
    "    1,\n",
    "    column_names=['group','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','C15','C16','C17','C18','C19'],\n",
    "    column_defaults=None,\n",
    "    label_name='group',\n",
    "    select_columns=None,\n",
    "    field_delim=',',\n",
    "    use_quote_delim=True,\n",
    "    na_value='',\n",
    "    header=False,\n",
    "    num_epochs=None,\n",
    "    shuffle=False,\n",
    "    shuffle_buffer_size=10000,\n",
    "    shuffle_seed=None,\n",
    "    prefetch_buffer_size=tf.data.experimental.AUTOTUNE,\n",
    "    num_parallel_reads=1,\n",
    "    sloppy=False,\n",
    "    num_rows_for_inference=100,\n",
    "    compression_type=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
